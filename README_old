README file explains how to set up moga optimization for a specific system
11/04/14
Casey Brock

socorro, dakota, dprepro, elk, and atompaw need to be in path.
Also, environment variable ELKROOT needs to be set to directory where elk is installed.

To run, input files 'configurations.in' and 'elk_forces.dat' need to be in opal directory.

configurations.in contains positions of all atoms in lattice coordinates where each row is a configuration and each column is a coordinate. 
See below for instructuions on generating this file.
Every three columns represents an atom. 
Example containing 4 configurations, where atom 1 is at the origin for every configuration:
0.00000 0.00000 0.00000       0.50172 0.35220 0.62241
0.00000 0.00000 0.00000       0.57686 0.31290 0.50692
0.00000 0.00000 0.00000       0.54623 0.55380 0.60022
0.00000 0.00000 0.00000       0.57652 0.59206 0.31486


NOTE: forces in elk_forces.dat are in Hartree (not Rydbergs)
elk_force.dat contains the forces generated by elk for each configuration. 
See below for instructions on generating this file.
Only the "obj_fn_" columns are used. This file can be copied from a dakota_tabular.dat file. Example containing 4 configurations and 6 force components (two atoms):
%eval_id           r1_a           r1_b           r1_c           r2_a           r2_b           r2_c       obj_fn_1       obj_fn_2       obj_fn_3       obj_fn_4       obj_fn_5       obj_fn_6
       1              0              0              0        0.50172         0.3522        0.62241     0.00905588    -0.01504372    -0.00034525    -0.00905588     0.01504372     0.00034525
       2              0              0              0        0.57686         0.3129        0.50692     0.00173881    -0.00433238    -0.02360459    -0.00173881     0.00433238     0.02360459
       3              0              0              0        0.54623         0.5538        0.60022     0.01086548      0.0029082     0.01333147    -0.01086548     -0.0029082    -0.01333147
       4              0              0              0        0.57652        0.59206        0.31486    -0.00471024     0.01970291    -0.00283324     0.00471024    -0.01970291     0.00283324

To start optimization, use command 
$ ./pp_moga.sh &>pp_moga.log
The script does a little bit of preprocessing, then runs a Dakota process. The Dakota process itself doesn't use much CPU, but it calls other scripts and spawns many jobs. I run it on Saturn to prevent the Dakota process from being killed for running too long.

The exe.info output file contains information about the Socorro, AtomPAW, and DAKOTA versions used.

The dakota_tabular.dat output file contains the design points and ojective functions for each design point tested.

The finaldata1.dat file contains the design variables and objectives for the Pareto front. 
We wrote a paretofind script to generate a better pareto front file. It can also generate intermediate pareto fronts if the optimization isn't finished


*** HOW TO SET UP MOGA RUN ************************************
***************************************************************
1) GENERATE RANDOM CONFIGURATIONS. Copy a random_configs/ directory from the examples/ directory. Edit random_configs.py for your crystal structure and number of configurations, and then run it to generate the configurations. Use plot_configs.py to visualize your configurations (edit lattice vectors if necessary). The configs.dat file that is generated can then be copied to this directory (the main optimization directory) and renamed to configurations.in. 



2) GENERATE REFERENCE SOLUTION WITH ELK.
First run an elk convergence study. I've automated this for the most part, but some system dependent paramters need to be changed. 
unpack examples/elk_converge_template.tar.gz into this directory (main moga diretory). 
This is the setup I used for hydrogen and only a few things should need to be changed for each sytem.There is a detailed README in the elk_converge_template on running the convergence study. There's another example in examples/SiO2/ using a hexagonal unit cell.
 
After the convergence study, the parameters have been determined for generating an accurate reference solution.
unpack examples/ref_solution_template.tar.gz into this directory (main moga diretory). 
As with the convergence study, there is a detailed README for the reference solution process explaining the steps for calculating the reference solution in more detail (ref_solution/README). 
The scripts will generate a dakota_tabular.dat file which will be renamed to elk_force.dat. This file contains the reference solution.



3) CREATE/EDIT MATERIAL DEPENDENT FILES/SCRIPTS
Examples of material dependent input files can be found in the examples directory. These need to be copied to appropriate places in the main moga directory or subdirectories and then edited for your material. At the bottom of this file you can find detailed instructions for each of these files.
Here's a list of these files and where they belong
opal.in
templatedir_pp/*.atompaw.template
scripts/dakota_pp.in
templatedir_pp/templatedir_gcut/templatedir/argvf.template
templatedir_pp/templatedir_gcut/templatedir/data/crystal.template



4) TEST RUN
The test run serves 3 purposes:
-sanity check: if socorro and elk didn't produce similar forces, setup could be wrong
-wall time estimate: gives an idea of how much wall time to request for jobs (step 5)
-atan objective weight: gives a sample of force atan objectives so the atan objectives can be scaled (step 6)

To set up, put a generous wall time estimate in opal.in. You will need to change both WALLTIME_LIMIT and SBATCH_FLAGS. 3 hours is a good estimate for small systems. The FORCE_WEIGHT and ATAN_WEIGHT should both be set to 1. 
In scripts/dakota_pp.in, change both population_size and max_function_evaluations to 300.

Run the test in a screen session on saturn (or on a compute node) using the command
./pp_moga.sh &> pp_moga_test.log

When the optimization is finished, unpack all the work directories so you can do the next couple steps
$ for f in workdir_pp.*.tar.gz; do tar -zxvf $f; done

Check the converged_forces.dat files in the workdir_pps and compare to forces in the elk_force.dat file. Keep in mind, the elk forces are in hartrees/bohr and the socorro forces are in rydbergs/bohr (2 rydberg = 1 hartree). Check the dakota_tabular.dat file to see which design points have the lowest accuracy objectives. Those are more likely to produce reasonable forces. The different design points will produce different forces and it is possible that none of them will be very accurate, but I consider the force components reasonably similar if they are the same order of magnitude and the same sign. If the forces are not reasonably similar, this could indicate a mistake in the input files or another problem. 



5) WALL TIME ESTIMATE
To examine wall time usage of the design points that completed, first run scripts/extract_walltimes.sh. 
(Note that walltimes are only reported for design points that completed without errors. Many will have errors such as when atompaw can't create a PP with the given design variables. these errors are normal and indicated by integers~=100 in the dakota_tabular.dat file)
$ bash scripts/extract_walltimes.sh > moga_test_walltimes.dat
Then use plots/walltime_distribution.py to plot the distribution of wall times.
$ cd plots; python walltime_distribution.py; cd ..
Now you want to choose a wall time to request for each of the jobs in the optimization. It seems like the walltimes follow an approximate exponential distribution. I haven't come up with a rigorous way to choose a wall time, but I choose a time where the distribution has flattened out so most points will be able to complete.

Now edit the wall time requested in opal.in. Note the wall time is listed in both the WALLTIME_LIMIT block (in seconds) and the SBATCH_FLAGS block. The SBATCH_FLAGS time should be 2 minutes longer.



6) ATAN WEIGHT
The accuracy objective for the optimization has two components, the force and atan objectives. 
I weight the atan objective so that the force/atan objectives are of similar magnitude for the lowest objectives (the objectives grow at different rates as accuracy get worse). 
The force, atan, and total accuracy objectives for each design point in the test run are reported in workdir_pp.*/accuracy_obj.log. These need to be unpacked from the tarballs
These data will help determine the proper weight for the atan objective.

If the work directories aren't already unpacked, just unpack accuracy objective files
$ for filename in workdir_pp.*.tar.gz; do tar -zxf $f *accuracy_obj.log; done
Run script to compile all accuracy objectives into single file
$ bash scripts/extract_all_accu.sh all_accu_obj_testrun.dat
Run script to calculate atan weight.
$ python scripts/calc_accu_weights.py all_accu_obj_testrun.dat
Write atan objective into opal.in. Round to 2 sig figs if you want since this is an approximation anyway. Leave force weight=1



7)  NUMBER OF GENERATIONS AND INITIAL GENERATION SIZE
Decide how big you want the first generation to be and how many generations you want. We have see that the pareto front doesn't change much after a few generations, so I think a good number of generations is 5. 
We haven't extensively studied the effect of initial generation size, but 300-1000 is probably reasonable for a few design variables. 
The maximum number of design points should be large enough that all generations can complete. A VERY rough estimate of the number of design points is max_iteration*population_size. Perhaps set max_function_evaluations to 4*max_iteration*population_size .

Change these variables in scripts/dakota_pp.in
max_iteration: maximum number of generations
population_size: size of first generation
max_function_evaluations: maximum number of design points that will be tested.



8) RUN MOGA!!! 
Start a screen session on Saturn. Use command:
./pp_moga.sh &> pp_moga.log
Detach from screen session.



9) MONITOR AND RESTART IF NECESSARY. 
The main file to watch is pp_moga.log. I check on the moga runs several times a day to make sure there hasn't been a problem. The design points and objectives for the generations that have completed are in dakota_tabular.dat. 
-Sometimes, a design point will finish but will get compressed before Dakota notices the results file. If this happens, Dakota will wait indefinitely. You can extract the directory and Dakota will see the results file and continue. 
-Sometimes, a computer error will cause  Dakota to either abort or get stuck waiting for a design point to finish that will never finish. If something goes wrong, Dakota can be killed (if it hasn't aborted already) and restarted. 

HOW TO KILL DAKOTA: 
From the node running the main dakota process, use
$ ps -ef | grep <username> 
to find process id of screen session running moga. Then set variable PID to the process id and kill that process and all its children: 
$ PID=<process id>
$ kill -- -$(ps -o pgid= $PID | grep -o '[0-9]*') 
Also kill any jobs related to the optimization. I use
$ scancel -u brockc
if I only have one optimization running

HOW TO RESTART MOGA
moga can be restarted with these commands from the screen session:
$ mv pp_moga.log pp_moga_0.log
$ dakota -i scripts/dakota_pp.in -r dakota.rst -s <n> -w dakota_restart1.rst &> pp_moga.log
where <n> is the last design point that completed succesfully. I like to rename the old pp_moga.log file just for record keeping. The most recent log file must always be named pp_moga.log because I am implementing a function that continually reads the log file.
If a second restart is required later:
$ mv pp_moga.log pp_moga_1.log
$ dakota -i scripts/dakota_pp.in -r dakota_restart1.rst -s <n2>-w dakota_restart2.rst &> pp_moga.log
and similarly for any later restarts.
***************************************************************


*** SOME SCRIPTS/FILES THAT PROBABLY NEED TO BE EDITED FOR DIFFERENT SYSTEMS
****************************************************************
configurations.in, contains generated random configurations (created in step 1)

elk_force.dat, crystal system specific forces generated with elk (created in step 2)

opal.in, needs to be edited several times in different steps  
in step 3: change element list, job name (in SBATCH_FLAGS)
in step 4: change wall time requested (generous estimate)
           make sure force and atan weights are 1
in step 5: change wall time requested (based on test run)
in step 6: change atan weight (based on test run)

- *.atompaw.template, there should be an atompaw input template for each atom in the crystal system in the templatedir_pp/ directory. The * should be the atomic symbol of the element. To create these templates, you can possibly modify an existing atompaw input from the atompaw website and replace the RCs and projector energies in the file with the Dakota design variable descriptors. The descriptors should match those in scripts/dakota_pp.in and should be enclosed in curly braces in the *.atompaw.template files.
EDIT: I have made templates for every element in /tplab/brockc/Every_Element_Template/. You can use these if you want. There is also an info file for each template that names the design variables and how many valence electrons there are. These may be helpful

- scripts/dakota_pp.in, needs to be edited several times in different steps
in step 3: change ***continuous_design*** to number of design variables. change ***design variables*** and ranges (see examples for help). The design variables should be the same as in *.atompaw.template. I usually set bounds to 0.2, 4.0 for cutoff radii and 0, 15 for projector energies. (initial_point isn't used)
in step 4: change population_size and max_function_evaluations to 300 
in step 7: change max_iteration, population_size, max_function_evaluations to whatever will be used for actual optimization

- templatedir_pp/templatedir_gcut/templatedir/argvf.template
make sure the kpoint grid ***mpparams*** matches what was used for elk
change ***nbands*** which will depend on the number of valence electrons being treated and the number of ions in the unit cell. The number of valence eletrons will depend on the valency of the pseudopotentials.
Based on the VASP documentation (http://cms.mpi.univie.ac.at/vasp/vasp/NBANDS_tag.html), I set nbands to NELECT/2 + 2*NIONS where NELECT is the number of valence electrons in the unit cell and NIONS is the number of ions in the unit cell. See comments in Every_Element_Template/ template files for the number of valence electrons in the pseudopotentials.

- templatedir_pp/templatedir_gcut/templatedir/data/crystal.template, 
optionally change descriptor on first line
change lattice vector scale. this should match ref_solution/elk.in.template.template
change lattice vectors if necessary
change number of atoms in lattice block
insert one row for each atom in unit cell. these descriptors should also match those in ref_solution/elk.in.template.template. 
******************************************************************
